---
title: "Initial FLUXNET Plots"
author: "Kristina Riemer & Dave Moore"
date: "`r Sys.Date()`"
format: html
editor: visual
---

## TODO list

- Data
- Plots
  - Scale by number of years for each date

## Prep data

### Read in libraries

::: {.callout-note}
Need dev version of `amerifluxr` package to get `amf_download_fluxnet` function. 
:::

```{r}
#| output: false
library(dplyr)
library(lubridate)
library(ggplot2)
#devtools::install_github("chuhousen/amerifluxr")
library(amerifluxr)
library(stringr)
library(readr)
library(purrr)
```

### Download site metadata

Showing what metadata is available for a site

```{r}
site_metadata <- amf_site_info()
site_metadata %>% 
  filter(SITE_ID == "US-SRM")
```
Do download setup

- Increase timeout because default of one minute isn't enough

```{r}
if (!dir.exists("data")){
  dir.create("data")
}

options(timeout = 600)
```

### Download individual site data

Demonstrating how to use `amf_download_fluxnet` function

```{r}
#| eval: false

amf_download_fluxnet(user_id = "kristinariemer", 
                     user_email = "kristinariemer@arizona.edu", 
                     site_id = "US-xSR", 
                     data_product = "FLUXNET",
                     data_variant = "FULLSET",
                     data_policy = "CCBY4.0",
                     agree_policy = TRUE, 
                     intended_use = "synthesis", 
                     intended_use_text = "creating pipeline for standardized figures", 
                     out_dir = "data/")
unzip("data/AMF_US-xSR_FLUXNET_FULLSET_2017-2021_3-5.zip")
```

### Download multiple sites data

This is for all of the Arizona sites, which includes all the sites in Dave's list. Gets list of sites that already have data downloaded (`downloaded_sites`). Then goes through each Arizona site and downloads the data if needed. If only BASE data is available, it returns the message `Cannot find data from [site]`. Downloads the zip file and unzips it. 

```{r}
#| eval: false

az_sites <- site_metadata %>% 
  filter(STATE == "AZ")

downloaded_sites <- list.dirs("data") %>% 
  str_split_i("_", 2)

for(site in az_sites$SITE_ID){
  if(!site %in% downloaded_sites){
    print(paste0("Downloading data for ", site))
    tryCatch({
      amf_download_fluxnet(user_id = "kristinariemer",
                           user_email = "kristinariemer@arizona.edu",
                           site_id = site,
                           data_product = "FLUXNET",
                           data_variant = "FULLSET",
                           data_policy = "CCBY4.0",
                           agree_policy = TRUE,
                           intended_use = "synthesis",
                           intended_use_text = "creating pipeline for standardized figures",
                           out_dir = "data/")
      zip_path <- Sys.glob(file.path("data", paste0("AMF_", site, "*")))
      unzipped_path <- tools::file_path_sans_ext(zip_path)
      unzip(zip_path, exdir = unzipped_path)
      }, error = function(e){cat("ERROR:",conditionMessage(e), "\n")})
    } else {
      print(paste0("Data has already been downloaded for ", site))
    }
}
```

### Read in data

Single site details

- Site: [US-SRM](https://ameriflux.lbl.gov/sites/siteinfo/US-SRM) (Santa Rita Mesquite)
- Years: 2004 - 2023
- IGBP: Woody Savannas

```{r}
single_site_daily <- read.csv("data/AMF_US-SRM_FLUXNET_FULLSET_2004-2023_3-6/AMF_US-SRM_FLUXNET_FULLSET_DD_2004-2023_3-6.csv")
single_site_hourly <- read.csv("data/AMF_US-SRM_FLUXNET_FULLSET_2004-2023_3-6/AMF_US-SRM_FLUXNET_FULLSET_HH_2004-2023_3-6.csv")
```

Multiple sites

```{r}
#| output: false

sites_paths <- list.files(".", pattern = "(FLUXNET_FULLSET_DD)", recursive = TRUE) 

multiple_sites_daily <- map_df(sites_paths, ~read_csv(.x) %>% mutate(file = basename(.x), .before = 1)) %>% 
  mutate(file = str_split_i(file, "_", 2)) %>% 
  rename(site = file)
```

## Create figures

All plots are for 3 variables: 

1. GPP_NT_VUT_REF
2. RECO_NT_VUT_REF
3. NEE_VUT_REF

### Entire time series - single site

Lots of ways to smooth time series (i.e., filter)

- Simple running mean from [this book chapter](https://cswr.nrhstat.org/timeseries)
- Takes mean of value and (n-1) / 2 values on either side of it
- Bigger window size = more averaging

```{r}
window_size <- 51
```

```{r}
#| code-fold: true
#| warning: false

total_ts_gpp <- single_site_daily %>% 
  mutate(date_object = ymd(TIMESTAMP), 
         running_mean_gpp = stats::filter(GPP_NT_VUT_REF, rep(1/window_size, window_size)))

yr_start_dates <- total_ts_gpp %>% 
  select(date_object) %>% 
  filter(grepl("-01-01", date_object)) %>% 
  pull()

ggplot(total_ts_gpp, aes(x = date_object, y = GPP_NT_VUT_REF)) + 
  geom_point(size = 0.5, color = "darkgrey") +
  geom_line(aes(y = running_mean_gpp), color = "blue", lwd = 1) +
  geom_vline(xintercept = yr_start_dates, color = "grey", alpha = 0.5) + 
  labs(x = "Date", y = "GPP (smoothed)") +
  theme_classic()

total_ts_reco <- single_site_daily %>% 
  mutate(date_object = ymd(TIMESTAMP), 
         running_mean_reco = stats::filter(RECO_NT_VUT_REF, rep(1/window_size, window_size)))

ggplot(total_ts_reco, aes(x = date_object, y = RECO_NT_VUT_REF)) + 
  geom_point(size = 0.5, color = "darkgrey") +
  geom_line(aes(y = running_mean_reco), color = "blue", lwd = 1) +
  geom_vline(xintercept = yr_start_dates, color = "grey", alpha = 0.5) + 
  labs(x = "Date", y = "RECO (smoothed)") +
  theme_classic()

total_ts_nee <- single_site_daily %>% 
  mutate(date_object = ymd(TIMESTAMP), 
         running_mean_nee = stats::filter(NEE_VUT_REF, rep(1/window_size, window_size)))

ggplot(total_ts_nee, aes(x = date_object, y = NEE_VUT_REF)) + 
  geom_point(size = 0.5, color = "darkgrey") +
  geom_line(aes(y = running_mean_nee), color = "blue", lwd = 1) +
  geom_vline(xintercept = yr_start_dates, color = "grey", alpha = 0.5) + 
  labs(x = "Date", y = "NEE (smoothed)") +
  theme_classic()
```

### Average annual time series - single site

Show average daily values (with standard deviations)

```{r}
#| code-fold: true
gpp_by_date <- single_site_daily %>% 
  mutate(date_object = ymd(TIMESTAMP), 
         date_minus_year = format(date_object, '%m-%d')) %>% 
  group_by(date_minus_year) %>% 
  summarize(gpp_mean = mean(GPP_NT_VUT_REF), 
            gpp_sd = sd(GPP_NT_VUT_REF)) %>% 
  mutate(date_fake_year = ymd(paste0("2024-", date_minus_year)))

ggplot(gpp_by_date, aes(x = date_fake_year, y = gpp_mean)) +
  geom_ribbon(aes(ymax = gpp_mean + gpp_sd, ymin = gpp_mean - gpp_sd), 
              fill = "grey") + 
    geom_point() +
    labs(x = "Date",
         y = "Mean GPP +/- SD") +
    theme_minimal() + 
  scale_x_date(date_labels = "%B")

reco_by_date <- single_site_daily %>% 
  mutate(date_object = ymd(TIMESTAMP), 
         date_minus_year = format(date_object, '%m-%d')) %>% 
  group_by(date_minus_year) %>% 
  summarize(reco_mean = mean(RECO_NT_VUT_REF), 
            reco_sd = sd(RECO_NT_VUT_REF)) %>% 
  mutate(date_fake_year = ymd(paste0("2024-", date_minus_year)))

ggplot(reco_by_date, aes(x = date_fake_year, y = reco_mean)) +
  geom_ribbon(aes(ymax = reco_mean + reco_sd, ymin = reco_mean - reco_sd), 
              fill = "grey") + 
    geom_point() +
    labs(x = "Date",
         y = "Mean RECO +/- SD") +
    theme_minimal() + 
  scale_x_date(date_labels = "%B")

nee_by_date <- single_site_daily %>% 
  mutate(date_object = ymd(TIMESTAMP), 
         date_minus_year = format(date_object, '%m-%d')) %>% 
  group_by(date_minus_year) %>% 
  summarize(nee_mean = mean(NEE_VUT_REF), 
            nee_sd = sd(NEE_VUT_REF)) %>% 
  mutate(date_fake_year = ymd(paste0("2024-", date_minus_year)))

ggplot(nee_by_date, aes(x = date_fake_year, y = nee_mean)) +
  geom_ribbon(aes(ymax = nee_mean + nee_sd, ymin = nee_mean - nee_sd), 
              fill = "grey") + 
    geom_point() +
    labs(x = "Date",
         y = "Mean NEE +/- SD") +
    theme_minimal() + 
  scale_x_date(date_labels = "%B")

```

### Average annual time series - multiple sites

Textbook figures: 

![](textbook_figures/seasonal_gpp_nee.png)


Show average daily values by site (symbols) and vegetation type (colors)

(Something wrong with GPP values for site US-LS2)

```{r}
#| code-fold: true
#| warning: false

gpp_by_date_sites <- multiple_sites_daily %>% 
  mutate(date_object = ymd(TIMESTAMP), 
         date_minus_year = format(date_object, '%m-%d')) %>% 
  group_by(site, date_minus_year) %>% 
  summarize(gpp_mean = mean(GPP_NT_VUT_REF), 
            gpp_sd = sd(GPP_NT_VUT_REF), 
            reco_mean = mean(RECO_NT_VUT_REF), 
            reco_sd = sd(RECO_NT_VUT_REF), 
            nee_mean = mean(NEE_VUT_REF), 
            nee_sd = sd(NEE_VUT_REF)) %>% 
  mutate(date_fake_year = ymd(paste0("2024-", date_minus_year))) %>% 
  left_join(site_metadata, by = c("site" = "SITE_ID")) %>% 
  filter(site != "US-LS2")

ggplot(gpp_by_date_sites, aes(x = date_fake_year, y = gpp_mean)) +
    geom_point(aes(color = IGBP, shape = site)) +
    labs(x = "Date",
         y = "Mean GPP") +
    theme_minimal() + 
  scale_x_date(date_labels = "%B")

ggplot(gpp_by_date_sites, aes(x = date_fake_year, y = reco_mean)) +
    geom_point(aes(color = IGBP, shape = site)) +
    labs(x = "Date",
         y = "Mean RECO") +
    theme_minimal() + 
  scale_x_date(date_labels = "%B")

ggplot(gpp_by_date_sites, aes(x = date_fake_year, y = nee_mean)) +
    geom_point(aes(color = IGBP, shape = site)) +
    labs(x = "Date",
         y = "Mean NEE") +
    theme_minimal() + 
  scale_x_date(date_labels = "%B")
```
### Daily energy flux

Textbook figures: 

![](textbook_figudaily_energy_flux.png)

Ameriflux variables: 

- NETRAD: Net radiation
- SW_IN: Shortwave radiation, incoming
- SW_OUT: Shortwave radiation, outgoing
- LW_IN: Longwave radiation, incoming
- LW_OUT: Longwave radiation, outgoing

```{r}
rad_means <- single_site_hourly %>% 
  mutate(date_object = ymd_hm(TIMESTAMP_START), 
         time = format(as.POSIXct(date_object), format = '%H:%M')) %>% 
  group_by(time) %>% 
  summarise(rn_mean = mean(NETRAD))


ggplot(rad_means, aes(x = time, y = rn_mean)) +
  geom_point() +
  labs(x = "Time",
       y = "Energy flux") +
  theme_minimal() #+
  #scale_x_time(breaks = "2 hours")

```

